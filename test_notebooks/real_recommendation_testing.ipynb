{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/large_dataset/correct_trajectories.pkl\")\n",
    "label_dict = {genre: idx for idx, genre in enumerate(df[\"genre\"].unique())}\n",
    "df[\"name\"] = df[\"file\"].apply(lambda x: x.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = np.concatenate(df[\"trajectory\"].to_numpy()).reshape(-1, 10, 768)\n",
    "names = df[\"name\"].to_numpy()\n",
    "genres = df[\"genre\"].to_numpy()\n",
    "labels = np.array([label_dict[genre] for genre in genres])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "liked_names = [\n",
    "    \"data/large_dataset/80s_pop/Culture Club - Karma Chameleon (Official Music Video).mp3\",\n",
    "    \"data/large_dataset/80s_pop/Daryl Hall & John Oates - You Make My Dreams (Official HD Video).mp3\",\n",
    "    \"data/large_dataset/90s_hiphop/Wu-Tang Clan - C.R.E.A.M. (Official HD Video).mp3\",\n",
    "    \"data/large_dataset/2000s_alt_rock/MGMT - Electric Feel (Official HD Video).mp3\",\n",
    "    \"data/large_dataset/2000s_alt_rock/Red Hot Chili Peppers - Californication (Official Music Video) [HD UPGRADE].mp3\",\n",
    "    \"data/large_dataset/2000s_alt_rock/Green Day - 21 Guns [Official Music Video].mp3\",\n",
    "    \"data/large_dataset/2000s_rnb/Dr. Dre - Still D.R.E. ft. Snoop Dogg.mp3\",\n",
    "    \"data/large_dataset/2010s_hiphop/Outkast - Hey Ya! (Official HD Video).mp3\",\n",
    "    \"data/large_dataset/2010s_pop/The Weeknd - I Feel It Coming ft. Daft Punk (Official Video).mp3\",\n",
    "    \"data/large_dataset/2010s_pop/Icona Pop - I Love It (feat. Charli XCX) [OFFICIAL VIDEO].mp3\"\n",
    "]\n",
    "\n",
    "# get all the trajectories for the liked songs from df\n",
    "liked = np.zeros((10, 10, 768))\n",
    "for i, name in enumerate(liked_names):\n",
    "    liked[i] = df[df[\"file\"] == name][\"trajectory\"].iloc[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221318/729346365.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trajs = torch.tensor(trajs).to('cuda').float()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "S = 10\n",
    "\n",
    "projections = torch.zeros((S, 768, 768)).to('cuda')\n",
    "for songlet in range(S):\n",
    "    A = torch.tensor(liked[songlet].T)\n",
    "    P = A @ torch.linalg.inv((A.T  @ A)) @ A.T\n",
    "    projections[songlet] = P\n",
    "\n",
    "trajs = torch.tensor(trajs).to('cuda').float()\n",
    "\n",
    "projected_songs = torch.zeros_like(trajs).to('cuda')\n",
    "# test_projected = np.zeros(trajs.shape)\n",
    "for song in range(trajs.shape[0]):\n",
    "    projected_songs[song, :, :] = torch.matmul(projections, trajs[song, :, :, None]).squeeze(-1)\n",
    "    # for songlet in range(S):\n",
    "    #     proj = projections[songlet] @ trajs[song, songlet, :].cpu().numpy()\n",
    "    #     test_projected[song, songlet, :] = proj.cpu().numpy()\n",
    "\n",
    "norms = torch.norm((projected_songs - trajs), dim=2, p=2)\n",
    "norms = torch.sum(norms, dim=1)\n",
    "_, indices = torch.sort(norms, descending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((projected_songs.cpu().numpy() - test_projected)) < 1e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.71662795e-02,  1.20163759e-01, -7.52040571e-03, ...,\n",
       "          3.16209413e-02,  1.04000703e-02,  4.73817632e-02],\n",
       "        [ 5.74216333e-03,  1.11221152e-01, -5.38646326e-03, ...,\n",
       "          1.04357192e-02,  3.64602294e-03,  4.77864106e-02],\n",
       "        [ 3.06438674e-03,  1.13538607e-01, -3.10798987e-03, ...,\n",
       "          1.95053729e-02, -2.30626981e-03,  3.06339066e-02],\n",
       "        ...,\n",
       "        [-7.66425553e-03,  1.12982334e-01, -3.28348117e-03, ...,\n",
       "          1.50592402e-02,  2.53033171e-02,  3.60859051e-02],\n",
       "        [-4.15818992e-03,  1.08898357e-01, -2.53862109e-03, ...,\n",
       "          2.59745643e-02,  7.49649499e-03,  2.47891060e-02],\n",
       "        [-5.31231430e-03,  1.12038625e-01,  2.60447137e-03, ...,\n",
       "          2.40933087e-02,  4.55014151e-03,  2.52892498e-02]],\n",
       "\n",
       "       [[-7.83285096e-04,  1.13317639e-01, -5.46388898e-04, ...,\n",
       "          1.29219945e-02,  1.72969052e-02,  3.95846839e-02],\n",
       "        [ 1.18066044e-02,  1.14307357e-01, -5.32846524e-04, ...,\n",
       "          8.39496195e-03,  1.37434444e-02,  4.55275218e-02],\n",
       "        [ 8.27434295e-03,  1.15583140e-01,  3.33771891e-03, ...,\n",
       "          1.50447495e-02,  1.48792057e-03,  2.79330692e-02],\n",
       "        ...,\n",
       "        [-8.43696866e-05,  1.13035364e-01,  7.94808051e-04, ...,\n",
       "          1.38994903e-02,  2.81185454e-02,  4.26594506e-02],\n",
       "        [-1.35639540e-03,  1.20986313e-01,  1.80167108e-03, ...,\n",
       "          1.74562502e-02,  4.52350180e-03,  3.85500787e-02],\n",
       "        [ 1.98921380e-04,  1.20036856e-01,  2.70976559e-03, ...,\n",
       "          2.07492792e-02,  2.47172356e-03,  2.20568064e-02]],\n",
       "\n",
       "       [[ 4.94298409e-03,  1.13333370e-01, -7.54110840e-03, ...,\n",
       "          2.36250720e-02,  6.99308244e-03,  5.18579049e-02],\n",
       "        [ 1.35315564e-02,  1.07002374e-01, -3.50786281e-03, ...,\n",
       "          1.27335258e-02,  1.13736119e-02,  4.28538729e-02],\n",
       "        [ 4.16028191e-03,  1.14184924e-01, -1.49610289e-03, ...,\n",
       "          1.91972836e-02, -1.01346410e-02,  2.53798123e-02],\n",
       "        ...,\n",
       "        [-8.93325332e-03,  1.11161522e-01, -5.90753024e-03, ...,\n",
       "          1.17485946e-02,  2.57221193e-02,  3.45044909e-02],\n",
       "        [-1.14719490e-03,  1.11220190e-01, -2.06809417e-05, ...,\n",
       "          2.41407536e-02,  3.21303961e-03,  2.79399365e-02],\n",
       "        [ 9.53204086e-03,  1.17792413e-01, -2.27951600e-04, ...,\n",
       "          2.43878682e-02,  1.34021020e-02,  2.21000195e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.02159078e-02,  1.12316818e-01, -1.84841581e-03, ...,\n",
       "          1.49043882e-02,  2.14656601e-02,  3.39147058e-02],\n",
       "        [ 1.45633473e-02,  1.14659820e-01, -2.13503327e-03, ...,\n",
       "          1.78406477e-02,  8.32358941e-03,  3.14933366e-02],\n",
       "        [ 4.78069571e-03,  1.17751958e-01,  5.18513037e-03, ...,\n",
       "          7.23254310e-03, -5.00344774e-04,  2.54974769e-02],\n",
       "        ...,\n",
       "        [ 1.97604578e-02,  1.08256163e-01,  6.42085700e-03, ...,\n",
       "          1.37241893e-02,  4.45517876e-02,  4.20316526e-02],\n",
       "        [ 3.76098212e-03,  1.17059130e-01, -1.55537362e-03, ...,\n",
       "          1.84683368e-02,  2.32692141e-02,  6.05622532e-02],\n",
       "        [ 1.05055692e-02,  1.09184847e-01,  1.50689764e-02, ...,\n",
       "          2.13901437e-02,  7.79496952e-03,  1.97317336e-02]],\n",
       "\n",
       "       [[ 1.05489777e-03,  1.04195235e-01,  1.27654285e-03, ...,\n",
       "         -4.41229517e-04,  2.31562902e-02,  2.73890197e-02],\n",
       "        [ 2.08930512e-02,  9.06993434e-02,  3.35848209e-04, ...,\n",
       "          1.94146575e-02,  3.64617337e-02,  1.26709634e-02],\n",
       "        [-7.55476535e-03,  9.95755754e-02,  8.09395070e-03, ...,\n",
       "          5.27140425e-03,  1.98369347e-02,  2.44820283e-02],\n",
       "        ...,\n",
       "        [ 3.11489578e-02,  9.91576433e-02,  8.65941316e-03, ...,\n",
       "          6.90203363e-03,  4.30617899e-02,  4.86863856e-02],\n",
       "        [ 1.58365246e-02,  1.11094731e-01,  6.08498546e-03, ...,\n",
       "          3.59464220e-04,  2.98326880e-02,  6.45456577e-02],\n",
       "        [ 2.01109187e-02,  8.93001951e-02,  2.08332489e-02, ...,\n",
       "          1.90422363e-02,  1.96029246e-02,  1.72686170e-02]],\n",
       "\n",
       "       [[ 1.57109187e-02,  1.08888667e-01,  4.57672110e-03, ...,\n",
       "          1.59862945e-02,  3.15903423e-02,  3.19469383e-02],\n",
       "        [ 3.12656776e-02,  1.12487334e-01,  1.08693457e-03, ...,\n",
       "          2.11245861e-02,  3.06748795e-02,  1.19491447e-02],\n",
       "        [ 1.06982119e-02,  1.20720495e-01,  1.30116510e-04, ...,\n",
       "          1.38438994e-02,  1.30547702e-02,  2.21125998e-02],\n",
       "        ...,\n",
       "        [ 2.87279287e-02,  1.09013575e-01,  1.01709604e-02, ...,\n",
       "          8.12675294e-03,  3.58895474e-02,  5.06575189e-02],\n",
       "        [ 1.43609688e-02,  1.06027438e-01,  4.91804078e-03, ...,\n",
       "          3.98853485e-03,  3.78991058e-02,  6.66928642e-02],\n",
       "        [ 3.21590618e-02,  1.00277339e-01,  1.32158128e-03, ...,\n",
       "          6.83061865e-03,  3.03935387e-02,  5.87797662e-03]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/shrey/Documents/eecs448-boombox/real_recommendation_testing.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.241.212.241/home/shrey/Documents/eecs448-boombox/real_recommendation_testing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m projected \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmatmul(projs, trajs[\u001b[39m0\u001b[39;49m, :, :, \u001b[39mNone\u001b[39;49;00m])\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.241.212.241/home/shrey/Documents/eecs448-boombox/real_recommendation_testing.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m projected\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:757\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 757\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    758\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    759\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# projected = np.matmul(projs, trajs[0, :, :, None]).squeeze(-1)\n",
    "# projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 127.44 GiB (GPU 0; 7.92 GiB total capacity; 130.96 MiB already allocated; 7.05 GiB free; 132.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/shrey/Documents/eecs448-boombox/real_recommendation_testing.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.241.212.241/home/shrey/Documents/eecs448-boombox/real_recommendation_testing.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mmatmul(torch\u001b[39m.\u001b[39;49mtensor(projs)\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m), torch\u001b[39m.\u001b[39;49mtensor(trajs[:, :, :, \u001b[39mNone\u001b[39;49;00m])\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m))\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 127.44 GiB (GPU 0; 7.92 GiB total capacity; 130.96 MiB already allocated; 7.05 GiB free; 132.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch.matmul(torch.tensor(projs).to('cuda'), torch.tensor(trajs[:, :, :, None]).to('cuda')).squeeze(-1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
