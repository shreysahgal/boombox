{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from BoomboxProcessor import BoomboxProcessor\n",
    "from train_encoding_model import BoomboxNet\n",
    "from GenreClassifier import GenreClassifier\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torchmetrics.functional import accuracy as torch_acc\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Trajectory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 93 trajectories from 90s_hiphop\n",
      "Loaded 70 trajectories from 90s_rock\n",
      "Loaded 67 trajectories from 2010s_pop\n",
      "Loaded 60 trajectories from classical\n",
      "Loaded 75 trajectories from country\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:00<00:00, 112.22it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 114.33it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 121.28it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 101.12it/s]\n",
      "100%|██████████| 75/75 [00:00<00:00, 124.59it/s]\n"
     ]
    }
   ],
   "source": [
    "data_folder = [\"90s_hiphop\", \"90s_rock\", \"2010s_pop\", \"classical\", \"country\"]\n",
    "\n",
    "boombox = BoomboxProcessor(verbose=True)\n",
    "boombox.load_trajectories(data_folder) # load trajectories\n",
    "boombox.load_encoding_model('models/model_50000.pt', BoomboxNet)\n",
    "boombox.encode_trajectories() # encode trajectories\n",
    "boombox.split_encoded_trajectories(10)\n",
    "trajectories, labels = boombox.get_all_songlet_trajectories() # get all songlet trajectories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Trajectory Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder()\n",
    "labels = one_hot_encoder.fit_transform(labels.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(trajectories, labels, test_size=0.30, random_state=42)\n",
    "# convert to torch tensors\n",
    "x_train = torch.tensor(x_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "x_test = torch.tensor(x_test).float()\n",
    "y_test = torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1], x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1], x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32., 20., 16., 13., 29.])\n"
     ]
    }
   ],
   "source": [
    "# does y_test contain all the genres?\n",
    "print(y_test.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(list(zip(x_train, y_train)), batch_size=8, shuffle=True)\n",
    "testDataLoader = DataLoader(list(zip(x_test, y_test)), batch_size=8, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(GenreCNN, self).__init__()\n",
    "        self.conv_group = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(in_features=128*1*48, out_features=num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_group(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = GenreCNN().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs\n",
    "num_epochs = 50\n",
    "\n",
    "# Initialize empty lists to store the training and test accuracy, and loss at each epoch\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.2919, Train Acc: 0.6275, Test Acc: 0.4455\n",
      "Epoch [2/50], Train Loss: 1.1068, Train Acc: 0.7882, Test Acc: 0.8182\n",
      "Epoch [3/50], Train Loss: 1.0936, Train Acc: 0.8118, Test Acc: 0.8727\n",
      "Epoch [4/50], Train Loss: 1.0839, Train Acc: 0.8118, Test Acc: 0.8636\n",
      "Epoch [5/50], Train Loss: 1.0879, Train Acc: 0.8118, Test Acc: 0.8727\n",
      "Epoch [6/50], Train Loss: 1.0809, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [7/50], Train Loss: 1.0762, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [8/50], Train Loss: 1.0764, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [9/50], Train Loss: 1.0763, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [10/50], Train Loss: 1.0803, Train Acc: 0.8118, Test Acc: 0.8727\n",
      "Epoch [11/50], Train Loss: 1.0792, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [12/50], Train Loss: 1.0765, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [13/50], Train Loss: 1.0767, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [14/50], Train Loss: 1.0766, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [15/50], Train Loss: 1.0764, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [16/50], Train Loss: 1.0757, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [17/50], Train Loss: 1.0752, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [18/50], Train Loss: 1.0749, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [19/50], Train Loss: 1.0752, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [20/50], Train Loss: 1.0749, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [21/50], Train Loss: 1.0754, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [22/50], Train Loss: 1.0753, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [23/50], Train Loss: 1.0759, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [24/50], Train Loss: 1.0751, Train Acc: 0.8157, Test Acc: 0.8727\n",
      "Epoch [25/50], Train Loss: 0.9809, Train Acc: 0.9216, Test Acc: 0.9909\n",
      "Epoch [26/50], Train Loss: 0.9053, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [27/50], Train Loss: 0.9052, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [28/50], Train Loss: 0.9050, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [29/50], Train Loss: 0.9050, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [30/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [31/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [32/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [33/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [34/50], Train Loss: 0.9050, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [35/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [36/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [37/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [38/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [39/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [40/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [41/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [42/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [43/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [44/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [45/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [46/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [47/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [48/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [49/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n",
      "Epoch [50/50], Train Loss: 0.9049, Train Acc: 1.0000, Test Acc: 0.9909\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Initialize training loss and accuracy\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for inputs, labels in trainDataLoader:\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.argmax(dim=1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss and accuracy\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    train_loss /= len(trainDataLoader.dataset)\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize test accuracy\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testDataLoader:\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Update test accuracy\n",
    "            test_correct += (outputs.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "    # Print the training and test accuracy and loss at each epoch\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Test Acc: {:.4f}'\n",
    "          .format(epoch+1, num_epochs, train_loss, train_acc, test_acc))\n",
    "\n",
    "    # Append the training and test accuracy and loss to the corresponding lists\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "    loss_list.append(train_loss)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'genre-classification-{}.pt'.format(num_epochs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 4, 0, 1, 4, 2, 4], device='cuda:0') tensor([0, 4, 4, 0, 1, 4, 2, 4], device='cuda:0')\n",
      "tensor([2, 3, 0, 0, 1, 2, 0, 0], device='cuda:0') tensor([2, 3, 0, 0, 1, 2, 0, 0], device='cuda:0')\n",
      "tensor([1, 2, 1, 4, 4, 0, 4, 0], device='cuda:0') tensor([1, 2, 1, 4, 4, 0, 4, 0], device='cuda:0')\n",
      "tensor([0, 4, 0, 4, 2, 3, 3, 3], device='cuda:0') tensor([0, 4, 0, 4, 2, 3, 3, 3], device='cuda:0')\n",
      "tensor([1, 0, 1, 4, 4, 4, 2, 2], device='cuda:0') tensor([1, 0, 1, 4, 4, 4, 2, 2], device='cuda:0')\n",
      "tensor([1, 4, 1, 0, 0, 0, 4, 0], device='cuda:0') tensor([1, 4, 1, 0, 0, 0, 4, 0], device='cuda:0')\n",
      "tensor([1, 0, 0, 4, 2, 0, 0, 3], device='cuda:0') tensor([1, 0, 0, 4, 2, 0, 0, 3], device='cuda:0')\n",
      "tensor([1, 0, 1, 4, 1, 3, 4, 2], device='cuda:0') tensor([1, 0, 1, 4, 1, 3, 4, 2], device='cuda:0')\n",
      "tensor([3, 0, 0, 4, 0, 4, 4, 0], device='cuda:0') tensor([3, 0, 0, 4, 0, 4, 4, 0], device='cuda:0')\n",
      "tensor([4, 3, 2, 0, 2, 1, 4, 1], device='cuda:0') tensor([4, 3, 2, 0, 2, 1, 4, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 0, 1, 4, 1, 4], device='cuda:0') tensor([0, 0, 1, 0, 1, 4, 1, 4], device='cuda:0')\n",
      "tensor([2, 4, 2, 1, 3, 4, 3, 2], device='cuda:0') tensor([2, 4, 2, 1, 3, 2, 3, 2], device='cuda:0')\n",
      "tensor([0, 2, 3, 0, 0, 4, 4, 1], device='cuda:0') tensor([0, 2, 3, 0, 0, 4, 4, 1], device='cuda:0')\n",
      "tensor([4, 4, 0, 3, 1, 3], device='cuda:0') tensor([4, 4, 0, 3, 1, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = GenreCNN(num_classes=5).to('cuda')\n",
    "model.load_state_dict(torch.load('genre-classification-50.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Pass the test data through the model\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testDataLoader:\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        # Print the output predictions\n",
    "        print(outputs.argmax(dim=1), labels.argmax(dim=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
