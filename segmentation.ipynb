{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsteinig/.pyenv/versions/3.10.6/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from BoomboxProcessor import BoomboxProcessor\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torchmetrics.functional import accuracy as torch_acc\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from train_encoding_model import BoomboxNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsteinig/.pyenv/versions/3.10.6/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# First we need to trajectorize the data\n",
    "import librosa\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from MusicVectorizer import MusicVectorizer\n",
    "\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mert_model to instantiate a model of type hubert. This is not supported for all configurations of models and can yield errors.\n",
      " 15%|█▍        | 78/526 [02:44<08:48,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song too short\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 319/526 [11:25<07:27,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song too short\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 406/526 [14:07<03:27,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song too short\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [18:07<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "mv = MusicVectorizer()\n",
    "\n",
    "trajectories = dict()\n",
    "for song in tqdm(glob.glob(\"transformed_audio/*.mp3\")):\n",
    "    song_data = librosa.load(song, sr=SAMPLE_RATE)[0]\n",
    "    trajectories[song] = mv.trajectorize_song(song_data, SAMPLE_RATE)\n",
    "    \n",
    "np.save(\"data/salami_trajectories.npy\", trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folders = ['salami']\n",
    "bx = BoomboxProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx.load_trajectories(data_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx.load_encoding_model(\"models/model_50000.pt\", BoomboxNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx.encode_trajectories(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx.split_encoded_trajectories(10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "songlet_trajectories = bx.get_songlet_trajectories()['salami']\n",
    "timestep_trajectories = bx.get_trajectories()['salami']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "songlet_lengths = dict()\n",
    "for song in timestep_trajectories:\n",
    "    time = (timestep_trajectories[song].shape[0] * 5) / 10\n",
    "\n",
    "    songlet_lengths[song] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "salami_ids = list()\n",
    "for key in songlet_trajectories:\n",
    "    salami_ids.append(key.split('/')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SegmentationLabels import SegmentationLabels\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = SegmentationLabels(salami_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [00:00<00:00, 16476.38it/s]\n"
     ]
    }
   ],
   "source": [
    "annotations = dict()\n",
    "for salami_id in tqdm(salami_ids):\n",
    "    annotations[salami_id] = sl.get_annotation(salami_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "226\n",
      "300\n",
      "292\n",
      "859\n",
      "804\n",
      "182\n",
      "102\n",
      "96\n",
      "301\n",
      "256\n",
      "263\n",
      "174\n",
      "375\n",
      "246\n",
      "872\n",
      "67\n",
      "259\n",
      "1651\n",
      "61\n",
      "560\n",
      "69\n",
      "157\n",
      "419\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "NO_ANNO_DATA = []\n",
    "for annotation in annotations:\n",
    "    if len(annotations[annotation]) == 0:\n",
    "        # remove the song from the dataset\n",
    "        NO_ANNO_DATA.append(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "data = sl.get_annotation(61)\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
